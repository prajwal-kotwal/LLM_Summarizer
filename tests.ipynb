{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import google_api_key as GG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GG.Google_api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    'gemini-1.5-flash',\n",
    "    generation_config=genai.GenerationConfig(\n",
    "        max_output_tokens=20000,\n",
    "        temperature=0.9,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the summarization prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Summarize the following text in a clear, concise, and informative manner:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "def summarize_text(input_text):\n",
    "    # Format the prompt\n",
    "    prompt = PROMPT_TEMPLATE.format(text=input_text)\n",
    "    # Generate summary using the Gemini model\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " \n",
      "A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
      "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\n",
      "\n",
      "\n",
      "Summary:\n",
      " Paragraphs are organizational units in writing, grouping related sentences around a single topic.  They improve readability by clearly showing the structure of a longer text and aiding comprehension.  Paragraphs can contain various types of information, but all generally include a topic sentence to guide their content.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example text to summarize\n",
    "input_text = \"\"\"\n",
    "A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
    "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarize_text(input_text)\n",
    "print(\"Original Text:\\n\", input_text)\n",
    "print(\"\\nSummary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to 'summary.txt'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef read_pdf(file_path):\\n    with open(file_path, \\'rb\\') as file:\\n        reader = PyPDF2.PdfReader(file)\\n        text = \"\"\\n        for page in reader.pages:\\n            text += page.extract_text()\\n    return text\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read text from a PDF file\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_file_path = 'synopsis.pdf'  # Path to your PDF file\n",
    "input_text = read_pdf(pdf_file_path)\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarize_text(input_text)\n",
    "\n",
    "# Save the summary to a text file\n",
    "with open('summary.txt', 'w') as file:\n",
    "    file.write(summary)\n",
    "\n",
    "print(\"Summary saved to 'summary.txt'\")\n",
    "\n",
    "\n",
    "'''\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Four computer science students at Graphic Era (Deemed to be University) submitted a synopsis for their Bachelor of Technology project: an AI-powered text summarizer using Large Language Models (LLMs).  The project addresses the challenge of efficiently processing large volumes of text data by leveraging LLMs to generate concise, coherent summaries.  The project aims to develop a model that improves summary quality, offers personalization features, and evaluates performance against established benchmarks.  The proposed approach explores both extractive and abstractive summarization techniques, including TextRank, LexRank, transformer models, and hybrid methods, potentially utilizing fine-tuning and attention mechanisms.  The synopsis details hardware and software requirements and includes a literature review of relevant research.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef split_text_into_chunks(input_text, chunk_size=2000):\\n    # Split the text into chunks of approximately the specified size (in characters)\\n    chunks = []\\n    current_chunk = \"\"\\n    for line in input_text.splitlines():\\n        if len(current_chunk) + len(line) < chunk_size:\\n            current_chunk += line + \"\\n\"\\n        else:\\n            chunks.append(current_chunk)\\n            current_chunk = line + \"\\n\"\\n    if current_chunk:\\n        chunks.append(current_chunk)\\n    return chunks\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def split_text_into_chunks(input_text, chunk_size=2000):\n",
    "    # Split the text into chunks of approximately the specified size (in characters)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for line in input_text.splitlines():\n",
    "        if len(current_chunk) + len(line) < chunk_size:\n",
    "            current_chunk += line + \"\\n\"\n",
    "        else:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = line + \"\\n\"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    return chunks\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef summarize_chunks(chunks):\\n    summaries = []\\n    for chunk in chunks:\\n        summary = summarize_text(chunk)\\n        summaries.append(summary)\\n    return summaries\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def summarize_chunks(chunks):\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarize_text(chunk)\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef summarize_final_summary(summaries):\\n    final_text = \"\\n\".join(summaries)\\n    final_summary = summarize_text(final_text)\\n    return final_summary\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def summarize_final_summary(summaries):\n",
    "    final_text = \"\\n\".join(summaries)\n",
    "    final_summary = summarize_text(final_text)\n",
    "    return final_summary\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Main Execution\\npdf_file_path = \\'HP_goblet.pdf\\'  # Path to your large PDF\\ninput_text = read_pdf(pdf_file_path)\\n\\n# Step 1: Split the large text into smaller chunks\\nchunks = split_text_into_chunks(input_text, chunk_size=2000)\\n\\n# Step 2: Summarize each chunk\\nsummaries = summarize_chunks(chunks)\\n\\n# Step 3: Summarize the summaries into a final summary\\nfinal_summary = summarize_final_summary(summaries)\\n\\n# Save the final summary to a text file\\nwith open(\\'final_summary.txt\\', \\'w\\') as file:\\n    file.write(final_summary)\\n\\nprint(\"Final summary saved to \\'final_summary.txt\\'\")\\nprint(final_summary)\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Main Execution\n",
    "pdf_file_path = 'HP_goblet.pdf'  # Path to your large PDF\n",
    "input_text = read_pdf(pdf_file_path)\n",
    "\n",
    "# Step 1: Split the large text into smaller chunks\n",
    "chunks = split_text_into_chunks(input_text, chunk_size=2000)\n",
    "\n",
    "# Step 2: Summarize each chunk\n",
    "summaries = summarize_chunks(chunks)\n",
    "\n",
    "# Step 3: Summarize the summaries into a final summary\n",
    "final_summary = summarize_final_summary(summaries)\n",
    "\n",
    "# Save the final summary to a text file\n",
    "with open('final_summary.txt', 'w') as file:\n",
    "    file.write(final_summary)\n",
    "\n",
    "print(\"Final summary saved to 'final_summary.txt'\")\n",
    "print(final_summary)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
